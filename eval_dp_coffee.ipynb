{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    " \n",
    "\n",
    "import sys \n",
    "sys.path.append(\"/home/franka_deoxys/diffusion_policy\")\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import click\n",
    "import hydra\n",
    "import torch\n",
    "import dill\n",
    "import wandb\n",
    "import json\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.env_runner.robomimic_image_runner import RobomimicImageRunner\n",
    "\n",
    " \n",
    "import numpy as np \n",
    "import collections \n",
    "import tqdm\n",
    "import h5py\n",
    "import math \n",
    "import wandb.sdk.data_types.video as wv\n",
    "from diffusion_policy.gym_util.async_vector_env import AsyncVectorEnv\n",
    "from diffusion_policy.gym_util.sync_vector_env import SyncVectorEnv\n",
    "from diffusion_policy.gym_util.multistep_wrapper import MultiStepWrapper\n",
    "from diffusion_policy.gym_util.video_recording_wrapper import VideoRecordingWrapper, VideoRecorder\n",
    "from diffusion_policy.model.common.rotation_transformer import RotationTransformer\n",
    "\n",
    "from diffusion_policy.policy.base_image_policy import BaseImagePolicy\n",
    "from diffusion_policy.common.pytorch_util import dict_apply\n",
    "from diffusion_policy.env_runner.base_image_runner import BaseImageRunner\n",
    "from diffusion_policy.env.robomimic.robomimic_image_wrapper import RobomimicImageWrapper\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils \n",
    "from diffusion_policy.workspace.train_diffusion_unet_hybrid_workspace import TrainDiffusionUnetHybridWorkspace\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/home/franka_deoxys/deoxys_control/deoxys\")\n",
    "\n",
    "from deoxys import config_root\n",
    "from deoxys.franka_interface import FrankaInterface\n",
    "# from deoxys.utils import RobotStateRawObsDictGenerator, YamlConfig\n",
    "from deoxys.utils import  YamlConfig\n",
    "from deoxys.utils.config_utils import robot_config_parse_args\n",
    "from deoxys.utils.input_utils import input2action\n",
    "from deoxys.utils.io_devices import SpaceMouse\n",
    "from deoxys.utils.log_utils import get_deoxys_example_logger\n",
    "\n",
    "\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "\n",
    "from deoxys_vision.networking.camera_redis_interface import CameraRedisSubInterface\n",
    "from deoxys_vision.utils.camera_utils import assert_camera_ref_convention, get_camera_info\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "logger = get_deoxys_example_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "class FrameStackForTrans:\n",
    "    def __init__(self, num_frames):\n",
    "        self.num_frames = num_frames\n",
    "        self.obs_history = {}\n",
    "        \n",
    "    def reset(self, init_obs):\n",
    "        \"\"\" \n",
    "        init_obs: dict of initial observation at the start of the episode\n",
    "        return stacked obs by repeating the first observation num_frames times\n",
    "        \"\"\"\n",
    "        \n",
    "        self.obs_history = {}\n",
    "        for k in init_obs:\n",
    "            self.obs_history[k] = deque([init_obs[k][None] for _ in range(self.num_frames)], maxlen=self.num_frames,)\n",
    "        obs = { k : np.concatenate(self.obs_history[k], axis=0) for k in self.obs_history }\n",
    "        return obs \n",
    "\n",
    "    def add_new_obs(self, new_obs):\n",
    "        \"\"\" \n",
    "        new_obs: dict of new observation at current timestep\n",
    "        return stacked obs\n",
    "        \"\"\"\n",
    "        for k in new_obs:\n",
    "            if 'timesteps' in k or 'actions' in k: continue\n",
    "            self.obs_history[k].append(new_obs[k][None])\n",
    "\n",
    "        obs= { k : np.concatenate(self.obs_history[k], axis=0) for k in self.obs_history }\n",
    "        return obs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRawObsDictGenerator:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.last_obs_dict = None\n",
    "\n",
    "    def get_raw_obs_dict(self, state_info):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "           state_info (dict): A dictionary of robot state + images\n",
    "        \"\"\"\n",
    "        obs_dict = {}\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def load(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class RobotStateRawObsDictGenerator(BaseRawObsDictGenerator):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def load(self, obs_dict, key, value, check_valid=True):\n",
    "        \"\"\"\n",
    "        This is to check if the data is correct or not. Sometimes the data will be all zero depending on the networking conditions.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            (\n",
    "                np.sum(np.abs(value)) == 0.0\n",
    "                and key in [\"ee_states\", \"joint_states\", \"gripper_states\"]\n",
    "            )\n",
    "            and check_valid\n",
    "            and self.last_obs_dict is not None\n",
    "        ):\n",
    "            value = self.last_obs_dict[key]\n",
    "        obs_dict[key] = value\n",
    "\n",
    "    def get_raw_obs_dict(self, state_info):\n",
    "        last_state = state_info[\"last_state\"]\n",
    "        last_gripper_state = state_info[\"last_gripper_state\"]\n",
    "        obs_dict = {}\n",
    "\n",
    "        ee_states = np.array(last_state.O_T_EE)\n",
    "        joint_states = np.array(last_state.q)\n",
    "        gripper_states = np.array([last_gripper_state.width])\n",
    "\n",
    "        self.load(obs_dict, \"ee_states\", ee_states)\n",
    "        self.load(obs_dict, \"joint_states\", joint_states)\n",
    "        # Gripper widh will probably become zero\n",
    "        self.load(obs_dict, \"gripper_states\", gripper_states, check_valid=False)\n",
    "\n",
    "        for state in [\"ee_states\", \"joint_states\", \"gripper_states\"]:\n",
    "            if (\n",
    "                np.sum(np.abs(obs_dict[state])) <= 1e-6\n",
    "                and self.last_obs_dict is not None\n",
    "            ):\n",
    "                print(f\"{state} missing!!!!\")\n",
    "                obs_dict[state] = self.last_obs_dict[state]\n",
    "        self.last_obs_dict = obs_dict\n",
    "        return obs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.warn(\"This is a very dummy control policy!!!!!\")\n",
    "\n",
    "args = robot_config_parse_args()\n",
    "robot_interface = FrankaInterface(os.path.join(config_root, args.interface_cfg))\n",
    "controller_cfg = YamlConfig(\n",
    "    os.path.join(config_root, args.controller_cfg)\n",
    ").as_easydict()\n",
    "controller_type = args.controller_type\n",
    "\n",
    "spacemouse = SpaceMouse(vendor_id=9583, product_id=50734)\n",
    "spacemouse.start_control()\n",
    "\n",
    "raw_obs_dict_generator = RobotStateRawObsDictGenerator()\n",
    "\n",
    "import time\n",
    "\n",
    "time.sleep(0.3)\n",
    "dummy_torch_model = torch.nn.Linear(7, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_gripper(open=True):\n",
    "    d=-1. if open else 1.0\n",
    "    action_close=np.array([ 0.,  0., -0.,  0.,  0., -0., d])\n",
    "    robot_interface.control(\n",
    "        controller_type=controller_type,\n",
    "        action=action_close,\n",
    "        controller_cfg=controller_cfg,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.info(\"Resetting to the initial configuration\")\n",
    "# reset_joints_to(robot_interface, joint_sequence[0])\n",
    "set_gripper(open=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_ids = [0, 1]\n",
    "# camera_ids = [0]\n",
    "cr_interfaces = {}\n",
    "\n",
    "use_depth = False\n",
    "for camera_id in camera_ids:\n",
    "    camera_ref=f\"rs_{camera_id}\"\n",
    "    assert_camera_ref_convention(camera_ref)\n",
    "    camera_info = get_camera_info(camera_ref)\n",
    "    print('---------****-----------')\n",
    "    print(camera_info)\n",
    "    print('--------------------------')\n",
    "    # camera_info=  {'camera_id': 0, 'camera_type': 'rs', 'camera_name': 'camera_rs_0'}\n",
    "# \n",
    "\n",
    "    cr_interface = CameraRedisSubInterface(camera_info=camera_info, use_depth=use_depth, redis_host='127.0.0.1')\n",
    "    cr_interface.start()\n",
    "    cr_interfaces[camera_id] = cr_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs(use_depth=False):\n",
    "    data = {}\n",
    "    for camera_id in camera_ids:\n",
    "        img_info = cr_interfaces[camera_id].get_img_info()\n",
    "        data[f\"camera_{camera_id}\"]=img_info\n",
    "\n",
    "        imgs = cr_interfaces[camera_id].get_img()\n",
    "    \n",
    "        color_img = imgs[\"color\"][..., ::-1]\n",
    "\n",
    "        # color_img = cv2.resize(color_img, (128, 128))  \n",
    "        # depth_img = cv2.resize(depth_img, (128, 128))\n",
    "\n",
    "        # color_img = cv2.resize(color_img, (224, 224))  \n",
    "        color_img = cv2.resize(color_img, None, fx=0.5, fy=0.5)\n",
    "\n",
    "        data[f\"camera_{camera_id}_color\"]=color_img\n",
    "\n",
    "        if use_depth:\n",
    "            depth_img = imgs[\"depth\"]\n",
    "            depth_img = cv2.resize(depth_img, (224, 224)) \n",
    "            data[f\"camera_{camera_id}_depth\"]=depth_img\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_imgs()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_imgs()\n",
    "img_wrist = data['camera_0_color']\n",
    "img_front = data['camera_1_color']\n",
    "\n",
    "agentview_rgb=img_wrist \n",
    "eye_in_hand_rgb=img_front\n",
    "agentview_rgb.shape, eye_in_hand_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(agentview_rgb[:,:,::-1])\n",
    "plt.subplot(122)\n",
    "plt.imshow(eye_in_hand_rgb[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_obs(robot_interface):\n",
    "    last_state = robot_interface._state_buffer[-1]\n",
    "    last_gripper_state = robot_interface._gripper_state_buffer[-1]\n",
    "\n",
    "    obs_dict = raw_obs_dict_generator.get_raw_obs_dict(\n",
    "    {\"last_state\": last_state, \"last_gripper_state\": last_gripper_state})\n",
    "    # obs_dict={} #rgb only \n",
    "\n",
    "    data = get_imgs()\n",
    "    img_wrist = data['camera_0_color']\n",
    "    img_front = data['camera_1_color']\n",
    "\n",
    "    agentview_rgb=img_wrist\n",
    "    eye_in_hand_rgb=img_front\n",
    "    # agentview_rgb=cv2.resize(img_wrist, (120, 120))  \n",
    "    # eye_in_hand_rgb=cv2.resize(img_front, (120, 120)) \n",
    "\n",
    "    # agentview_rgb.shape, eye_in_hand_rgb.shape\n",
    "\n",
    "    obs_dict['agentview_rgb']=agentview_rgb.transpose(2, 1, 0)\n",
    "    obs_dict['eye_in_hand_rgb']=eye_in_hand_rgb.transpose(2, 1, 0)\n",
    "    return obs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dict=get_current_obs(robot_interface)\n",
    "for key in obs_dict.keys():\n",
    "    obs_dict[key]=obs_dict[key][None]\n",
    "    print(key, obs_dict[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load dp policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"/home/franka_deoxys/data_franka/dp_policy/coffee_after_train.ckpt\"\n",
    "\n",
    "payload = torch.load(open(checkpoint, 'rb'), pickle_module=dill)\n",
    "cfg = payload['cfg'] \n",
    "workspace = TrainDiffusionUnetHybridWorkspace(cfg, output_dir=None)\n",
    "workspace: BaseWorkspace\n",
    "workspace.load_payload(payload, exclude_keys=None, include_keys=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get policy from workspace\n",
    "policy = workspace.model\n",
    "if cfg.training.use_ema:\n",
    "    policy = workspace.ema_model\n",
    "\n",
    "device = torch.device(device)\n",
    "policy.to(device)\n",
    "policy.eval()\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_transformer = RotationTransformer('axis_angle', 'rotation_6d')\n",
    "\n",
    "def undo_transform_action( action):\n",
    "    raw_shape = action.shape\n",
    "    if raw_shape[-1] == 20:\n",
    "        # dual arm\n",
    "        action = action.reshape(-1,2,10)\n",
    "\n",
    "    d_rot = action.shape[-1] - 4\n",
    "    pos = action[...,:3]\n",
    "    rot = action[...,3:3+d_rot]\n",
    "    gripper = action[...,[-1]]\n",
    "    rot = rotation_transformer.inverse(rot)\n",
    "    uaction = np.concatenate([\n",
    "        pos, rot, gripper\n",
    "    ], axis=-1)\n",
    "\n",
    "    if raw_shape[-1] == 20:\n",
    "        # dual arm\n",
    "        uaction = uaction.reshape(*raw_shape[:-1], 14)\n",
    "\n",
    "    return uaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path=\"/media/franka_deoxys/DATA/demo_rss_paper/dec20/hdfs/ola_114.hdf5\"\n",
    "\n",
    "# f= h5py.File(dataset_path, 'r')\n",
    "# demos= f['data']\n",
    "# len(demos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo=f['data']['demo_1']\n",
    "# actions_org=demo['actions']\n",
    "# obss=demo['obs']\n",
    "# actions_org.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_action(obs):\n",
    "    \"\"\" \n",
    "    obs: 2x...\n",
    "    \"\"\"\n",
    "    np_obs_dict = {key:obs[key] for key in keys_select}\n",
    "    obs_dict = dict_apply(np_obs_dict, \n",
    "        lambda x: torch.from_numpy(x).to(\n",
    "            device=device))\n",
    "\n",
    "    for key in obs_dict.keys():\n",
    "        obs_dict[key]=obs_dict[key].unsqueeze(0) \n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        action_dict = policy.predict_action(obs_dict)\n",
    "\n",
    "    # device_transfer\n",
    "    np_action_dict = dict_apply(action_dict, lambda x: x.detach().to('cpu').numpy())\n",
    "\n",
    "\n",
    "    # step env\n",
    "    env_action =  np_action_dict['action']\n",
    "    env_action = undo_transform_action(env_action)\n",
    "\n",
    "    env_action=env_action.squeeze()\n",
    "    return env_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framestacker=FrameStackForTrans(2)\n",
    "keys_select = ['agentview_rgb', 'joint_states', 'ee_states', 'eye_in_hand_rgb', 'gripper_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "# obs = {k: obss[k][i] for k in obss.keys()}\n",
    "# obs['agentview_rgb'] = obs['agentview_rgb'].transpose(2,0,1)\n",
    "# obs['eye_in_hand_rgb'] = obs['eye_in_hand_rgb'].transpose(2,0, 1)\n",
    "\n",
    "# for k in obs.keys():\n",
    "#     print(k, obs[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dict=get_current_obs(robot_interface)\n",
    "for key in obs_dict.keys(): \n",
    "    print(key, obs_dict[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_pred=predict_action(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framestacker=FrameStackForTrans(2) \n",
    "policy.reset()\n",
    "\n",
    "obs_dict=get_current_obs(robot_interface)\n",
    "obs = framestacker.reset(obs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dict=get_current_obs(robot_interface)\n",
    "obs = framestacker.add_new_obs(obs_dict)\n",
    "action_pred=predict_action(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for act in action_pred:  \n",
    "    print(act.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.reset()\n",
    " \n",
    "for _ in range(500):\n",
    "    action, grasp = input2action(\n",
    "        device=spacemouse,\n",
    "        controller_type=controller_type,\n",
    "    )\n",
    "    if action is None:\n",
    "        break\n",
    "    if len(robot_interface._state_buffer) == 0:\n",
    "        continue\n",
    "\n",
    "    obs_dict=get_current_obs(robot_interface)\n",
    "    obs = framestacker.add_new_obs(obs_dict)\n",
    "    action_pred=predict_action(obs)\n",
    "\n",
    "    # print(f'actions: {action[0]:.3f} {action[1]:.3f} {action[2]:.3f} {action[-1]:.3f}')\n",
    "    \n",
    "    for action in action_pred:  \n",
    "        robot_interface.control(\n",
    "            controller_type=controller_type,\n",
    "            action=action,\n",
    "            controller_cfg=controller_cfg,\n",
    "        )\n",
    "\n",
    "    # time.sleep(0.045)\n",
    "\n",
    "    \n",
    "robot_interface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
